{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a447289ddddd6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T09:19:28.610703Z",
     "start_time": "2025-03-04T09:19:28.596110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6960c6d536e04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T09:19:42.178978Z",
     "start_time": "2025-03-04T09:19:28.901270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda\\envs\\bishe\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "D:\\ProgramFiles\\Anaconda\\envs\\bishe\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "03/04/2025 17:19:42 - INFO - qwen_vl_utils.vision_process -   set VIDEO_TOTAL_PIXELS: 90316800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 哈哈哈哈啊哈哈！\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token='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')\n",
    "\n",
    "sys.path.append('..')\n",
    "from easyeditor import (\n",
    "    FTHyperParams,\n",
    "    GraceHyperParams,\n",
    "    MEMITHyperParams,\n",
    "    ROMEHyperParams,\n",
    "    MENDHyperParams,\n",
    "    WISEHyperParams,\n",
    "    BaseEditor,\n",
    "    summary_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T09:20:24.033823Z",
     "start_time": "2025-03-04T09:19:44.648908Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 17:19:45,830 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "03/04/2025 17:19:45 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See results at:  ./outputs\\Llama-3.2-1B-Instruct_WISE_N=10_Sequential=True.json\n",
      "We are creating the logger files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 17:19:54,943 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "03/04/2025 17:19:54 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.45it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights successfully inserted into model.layers[12].mlp.down_proj.weight\n",
      "Executing WISE algorithm for the update: \n",
      "[When was the inception of IAAF Combined Events Challenge?] -> [2006]\n",
      "loss 38.188 = 8.188 + 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:19<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = SimpleNamespace(\n",
    "    editing_method = 'WISE',            # 必填参数\n",
    "    hparams_dir = '../myhparams/WISE/llama3.2-1b.yaml',          # 超参数目录\n",
    "    data_dir = '../data/wise',                # 数据目录\n",
    "    data_type = 'ZsRE',             # 数据类型\n",
    "    output_dir ='exp0/outputs',           # 输出目录\n",
    "    ds_size = 10,                        # 数据集大小\n",
    "    sequential_edit = True              # 是否顺序编辑\n",
    ")\n",
    "\n",
    "    \n",
    "if args.editing_method == 'FT':\n",
    "    editing_hparams = FTHyperParams\n",
    "elif args.editing_method == 'MEMIT':\n",
    "    editing_hparams = MEMITHyperParams\n",
    "elif args.editing_method == 'ROME':\n",
    "    editing_hparams = ROMEHyperParams\n",
    "elif args.editing_method == 'MEND':\n",
    "    editing_hparams = MENDHyperParams\n",
    "elif args.editing_method == 'GRACE':\n",
    "    editing_hparams = GraceHyperParams\n",
    "elif args.editing_method == 'WISE':\n",
    "    editing_hparams = WISEHyperParams\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "K = args.ds_size\n",
    "\n",
    "if args.data_type == 'ZsRE':\n",
    "    edit_data = json.load(open(f'{args.data_dir}/{args.data_type}/zsre_mend_edit.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_data = json.load(open(f'{args.data_dir}/{args.data_type}/zsre_mend_train.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_prompts = [edit_data_['loc'] + ' ' + edit_data_['loc_ans'] for edit_data_ in loc_data]\n",
    "\n",
    "    prompts = [edit_data_['src'] for edit_data_ in edit_data]\n",
    "    subject = [edit_data_['subject'] for edit_data_ in edit_data]\n",
    "    rephrase_prompts = [edit_data_['rephrase'] for edit_data_ in edit_data]\n",
    "    target_new = [edit_data_['alt'] for edit_data_ in edit_data]\n",
    "    locality_prompts = [edit_data_['loc'] for edit_data_ in edit_data]\n",
    "    locality_ans = [edit_data_['loc_ans'] for edit_data_ in edit_data]\n",
    "    locality_inputs = {\n",
    "        'neighborhood':{\n",
    "            'prompt': locality_prompts,\n",
    "            'ground_truth': locality_ans\n",
    "        },\n",
    "    }\n",
    "elif args.data_type == 'hallucination':\n",
    "    edit_data = json.load(open(f'{args.data_dir}/{args.data_type}/hallucination-edit.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_data = json.load(open(f'{args.data_dir}/{args.data_type}/hallucination-train.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_prompts = [edit_data_['locality_prompt'] + ' ' + edit_data_['locality_ground_truth'] for edit_data_ in loc_data]\n",
    "\n",
    "    prompts = [edit_data_['prompt'] for edit_data_ in edit_data]\n",
    "    subject = [edit_data_['subject'] for edit_data_ in edit_data]\n",
    "    rephrase_prompts = None\n",
    "    target_new = [edit_data_['target_new'] for edit_data_ in edit_data]\n",
    "    locality_prompts = [edit_data_['locality_prompt'] for edit_data_ in edit_data]\n",
    "    locality_ans = [edit_data_['locality_ground_truth'] for edit_data_ in edit_data]\n",
    "    locality_inputs = {\n",
    "        'neighborhood': {\n",
    "            'prompt': locality_prompts,\n",
    "            'ground_truth': locality_ans\n",
    "        },\n",
    "    }\n",
    "elif args.data_type == 'temporal':\n",
    "    edit_data = json.load(open(f'{args.data_dir}/{args.data_type}/temporal-edit.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_data = json.load(open(f'{args.data_dir}/{args.data_type}/temporal-train.json', 'r', encoding='utf-8'))[:K]\n",
    "    loc_prompts = [edit_data_['locality_prompt'] + ' ' + edit_data_['locality_ground_truth'] for edit_data_ in loc_data]\n",
    "\n",
    "    prompts = [edit_data_['prompt'] for edit_data_ in edit_data]\n",
    "    subject = [edit_data_['subject'] for edit_data_ in edit_data]\n",
    "    rephrase_prompts = [edit_data_['ood_rephrase'] for edit_data_ in edit_data]\n",
    "    target_new = [edit_data_['target_new'] for edit_data_ in edit_data]\n",
    "    locality_prompts = [edit_data_['locality_prompt'] for edit_data_ in edit_data]\n",
    "    locality_ans = [edit_data_['locality_ground_truth'] for edit_data_ in edit_data]\n",
    "    locality_inputs = {\n",
    "        'neighborhood': {\n",
    "            'prompt': locality_prompts,\n",
    "            'ground_truth': locality_ans\n",
    "        },\n",
    "    }\n",
    "\n",
    "hparams = editing_hparams.from_hparams(f'{args.hparams_dir}')\n",
    "\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "output_file = os.path.join(\n",
    "    args.output_dir,\n",
    "    f'{hparams.model_name.split(\"/\")[-1]}_{args.editing_method}_N={args.ds_size}_Sequential={args.sequential_edit}.json'\n",
    "    )\n",
    "\n",
    "print(\"See results at: \", output_file)\n",
    "\n",
    "eval_metric = {\n",
    "    'ZsRE': 'token em',\n",
    "    'hallucination': 'ppl',\n",
    "    'temporal': 'ood_ppl'\n",
    "}\n",
    "\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    rephrase_prompts=rephrase_prompts,\n",
    "    target_new=target_new,\n",
    "    loc_prompts=loc_prompts,\n",
    "    subject=subject,\n",
    "    locality_inputs=locality_inputs,\n",
    "    sequential_edit=args.sequential_edit,\n",
    "    eval_metric=eval_metric[args.data_type]\n",
    ")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "if len(metrics) > 0:\n",
    "    summary_metrics(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bcf8b3a38525d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
